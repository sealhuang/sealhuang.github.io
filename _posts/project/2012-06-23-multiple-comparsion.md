---
layout: post
title: 多重比较校正中的一些概念
category: project
description: 多重比较矫正的相关概念和方法,以及其在 fMRI 数据分析中的应用。
---

有些东西，隔段时间不看可能会遗忘，更可怕的是变形。记住了谬误比忘记更值得反省。

关于多重比较校正，虽然曾经查过很多东西，也大概记住一些，但最近发现没留下多少正确的印象。所以又温习了一遍，稍加整理，留备后用。当然，这些还是我自己的理解，如果有不对的地方，还请指出 :)

主要内容均来自wikipedia以及[这个网页][p_faq].

假设我们手上有一枚硬币，想通过抛10次硬币的方法检验它的金属分布是否均匀，结果发现扔10次，有9次国徽朝上。此时我们打算下结论说它的分布不均匀，恐怕被人动了手脚。但这个判断的正确性有多大，在统计上就需要用 p-value 来衡量。p-value 就是在原假设（Null hypothesis）为真时，得到和试验数据一样极端（或更极端）的统计量的概率；它本质上控制 false positive rate (FPR)。我们常说的 p 小于0.05即是说发现的现象为假阳性结果的概率小于5%。

如果我们手上有10000枚上文提到的相同的硬币要检验呢？假设针对每枚硬币依然采用以上的方法，则这10000次检验完全不出错的概率只有 (1 - 0.05) ** 10000。这在很多情况下不能接受的。此时我们面对的不再是 single test 问题，而是 multiple test。需要控制的是 family wise error rate (FWER)。一种很经典的控制FWER的方法是 [Bonferroni correction][bonf_link]。比如我们设定FWER为0.05，则可以将所有10000次检验中，出现错误的概率控制在5%以内。

但面对 fMRI 这样的数据，Bonferroni correction 则显得不太合适了。Bonferroni correction 是否适用，取决于数据是否服从一个基本假设：即每次 test 是否独立。像上面举的抛硬币的例子，每抛一次，显然都是独立事件。但像 fMRI 这样邻近 voxel 的信号往往具有高相关的数据，Bonferroni 矫正显然不太适用了。为了针对这种情况，人们选择使用了 Random-field Theory (RFT) 进行 FWE correction。其基本假设就是空间邻近的 voxel 具有相关（也可以说是存在由空间平滑造成的相关），则在检验前，先估算数据的平滑程度，再基于这一指标计算某个 voxel 不是由随机因素引起激活的概率。这种方法相对前一种相对宽松很多，但研究发现，其假设要求平滑程度至少要为数据最小空间分辨率的2-3倍（而且平滑程度越大，检验效果越宽松），使得许多研究无法采用此方法，同时也有研究表明这种矫正方式同样过于严格。

鉴于以上问题，以及对 FWE 概念的理解，随之我们采用了一种新的方法，[FDR][fdr_link]（False Discovery Rate）错误控制方法。FWE correction 保证的是在已通过多重比较校正的显著的检验中，出现假阳性结果的概率不大于某一值（比如0.05），即发现的显著结果中出错（哪怕只有一个错误）的概率小于0.05。但研究者也都有一个信念：我们的数据是存在噪声的，我们希望知道这些显著的结果中，有多少是真的。FDR 方法有效的控制了在这些阳性结果中的错误出现率。比如在上文中提到的10000个检验中，只发现1000个阳性结果，即硬币质量分布不均，则若控制FDR的q-value为0.05时，只对这1000个检验进行操作，并保证最后经过校正的检验结果中出现假阳性的结果的数量不多于50个（1000 * 0.05）。相对 FWER，FDR 在对结果的控制上显然要宽松很多，同时也给研究带来了更多的“有效”结果。需要提一下的是，在 FDR 校正中，对于 p-value 最小的检验，其校正的力度最大，随 p-value 增大，校正力度逐渐减小，这也体现了其减少假阳性结果的目的。

[p_faq]: http://mindhive.mit.edu/book/export/html/90 "P threshold FAQ"
[bonf_link]: http://en.wikipedia.org/wiki/Bonferroni_correction "Bonferroni correction"
[fdr_link]: http://en.wikipedia.org/wiki/False_discovery_rate "False discovery rate"
